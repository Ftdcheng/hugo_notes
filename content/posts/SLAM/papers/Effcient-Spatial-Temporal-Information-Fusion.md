---
title: "高效时空信息融合的动态SLAM框架"
date: 2025-04-22
author: "Citrus Cheng"
tags: ["papers"]
---

# 高效时空信息融合的动态SLAM框架
## idea

1. 稀疏体素卷积虽然可以缓解计算压力，不过体素化会损失信息
2. 测距图像(Range Image)一种相对来说轻量级的表示，不过由于向后投影，会有边界模糊的问题。
3. 文章先对测距图像进行粗分割，然后对粗分割再进行稀疏体素卷积去修正分割结果。一定程度上缓解了边界模糊，提高了效率
4. 单帧的分割大多只能找出潜在移动的物体，少数针对单帧的工作可以找出实际运动的物体。
5. 要准确找出运动的物体，相对可靠的方法是采用多帧的数据去检测。不过这种方法可能会吃更多的算力
6. LMNet在提取时空特征的时候单纯地把多帧拼在一起，这种方法似乎效率不高
7. 文章提出使用双分支结构，先分别处理时间、空间信息，然后再使用运动指导的注意力融合时空信息。
8. 这篇文章声称自己是一种在线的方案。

## 历史上的方法
1. 基于清除地图的方法： 有的方法使用预创建的地图和当前的scan做比较，找出动态的部分，还有的直接对最后生成的带鬼影的地图，直接去除鬼影，还有的使用聚类技术和多物体跟踪的方式，跟踪不同的物体，基于跟踪结果生成基于激光雷达动态物体分割的训练标签，不过这种地图清除的方法多是离线的。
2. 在线MOS(运动物体分割):
    - 端到端的方法，从局部到整体一条龙。有些基于场景流的方法，在连续的两帧扫描中估计运动，使用每个点的速度估计物体是否运动。这种方法可能不能把噪声和缓慢移动的物体区分开。而且这种方法不能处理大规模的点云数据(100k)，实时性很难保证。
    - 从BBOX估计：先从点云里得到检测，从检测里得到BBOX，然后对BBOX进行跟踪，根据BBOX是否移动判断动态物体。

## 方法
### 测距图像的表示
$$
    \binom{u}{v}=\binom{\frac{1}{2}\left[1-\arctan (y, x) \pi^{-1}\right] \quad w}{\left[1-\left(\arcsin \left(z r^{-1}\right)+\mathrm{f}_{\mathrm{up}}\right) \mathrm{f}^{-1}\right] h}
$$

这个投影类似世界到相机的投影，与xoy平面的夹角相同，水平转角相同，但深度不同的点会投射到同一个uv坐标上。

### 残差图

使用帧间变换把前一帧k，转换到当前帧。然后把到当前帧的前一帧投影到uv空间中得到测距图像。然后把这个测距图像和当前帧的测距图像做归一化绝对差。

### 元核卷积（Meta-Kernel Convolution）

对于测距图像的残差图上的一个点，找它的3\*3相邻像素，我们知道每个像素对应一个3D坐标，对每个相邻像素，计算它到中心点的3D坐标差，然后把坐标差传进MLP，得到一个9元素的权重向量，然后把这个向量和3\*3的原始像素阵逐元素相乘。最后每个像素对应一个1\*1的特征图，即结果是1\*1\*8的张量，然后对这种张量进行1\*1的卷积得到最终的结果。

这么做的目的是编码3D空间信息。

